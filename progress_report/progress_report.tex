\documentclass[12pt]{article}
\usepackage{ulem}
\usepackage{apacite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[rgb]{xcolor}
\usepackage{natbib}
%\usepackage[a4paper,margin=2cm]{geometry}
\usepackage[colorlinks=true, urlcolor=blue, linkcolor=blue, citecolor=blue]{hyperref}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{definition}{Definition}[section]

\begin{document}
\title{\bf Progress report: Hanabi}
\author{Xiuhan Wang, Jing Wei}
\date{\today}
\maketitle

\section{Experimental Results}
We cloned the github repository \url{https://github.com/facebookresearch/hanabi_SAD} of the open-sourced code of Hanabi SAD with other-play \citep{hu2020other} and tried to run it. Since it is our first time to do a project, we spent a lot of time on dealing with environmental settings. We first tried to run it on our local machines using cpu, but there appeared to be a lot of problems, including pytorch versions and github repository versions (some repositories have been updated, but it seems the updated version can hardly be compiled successfully). Fortunately, though having spent a lot of time, we managed to solve them and made it run successfully on our machine.

After making it run successfully on our local machines, we rented some GPUs to train it. Because of the limitation of our computation resources, the results haven't converged yet and are worse than we expected. Table \ref{Tab1} is the scores (max 25) for the models in the first 500 epoches:
\begin{table}[H]
\begin{centering}
\begin{tabular}{|l|l|l|l|}
\hline
epoch & mean score & s.e.m. & perfect ratio \\ \hline
100 & 17.084 & 0.037 & 0.000 \\ \hline
200 & 17.116 & 0.035 & 0.001 \\ \hline  
300 & 17.160 & 0.035 & 0.001 \\ \hline
400 & 17.191 & 0.035 & 0.002 \\ \hline
500 & 17.245 & 0.033 & 0.003 \\ \hline
\end{tabular}
\caption{Performances after every 100 more epoches is trained.}
\label{Tab1}
\end{centering}
\end{table}

The trained model is Simplified Action Decoder (SAD) built on Independent Q-Learning (IQL). The number of players is $2$.

Wondering why our performance is so much worse than that in the original paper, we reread the original paper and code more carefully, we found out that only when trained about 1 million epoches can the model converge! However, with our resources, it takes almost one day to train $500$ epoches. Further more, the proposed ``SAD'' model was based on VDN, which converges faster than IQL. All these reasons made the result look bad. And it seems extremely hard to reproduce the results of the paper.

We also evaluated the models trained by the paper authors\citep{hu2020simplified}. We focus on 2-player settings. Table \ref{Tab2} compares the performances under different training settings:
\begin{table}[H]
\begin{centering}
\begin{tabular}{|l|l|l|l|}
\hline
method & mean score & s.e.m. & perfect ratio \\ \hline
IQL & 23.773 & 0.017 & 0.436 \\ \hline
VDN & 23.897 & 0.018 & 0.487 \\ \hline
SAD & 23.980 & 0.018 & 0.531 \\ \hline
SAD + Aux & 24.015 & 0.018 & 0.544 \\ \hline
\end{tabular}
\caption{Comparing performances under different training settings.}
\label{Tab2}
\end{centering}
\end{table}

We can observe that the model trained by SAD + Auxiliary tasks is the best. At the beginning epoches SAD may perform worse than the other settings, but when the model nearly converges, SAD is at a great advantage. So here comes a natural question: how can we evaluate the performance of a method when our computation resources are limited?

\section{Theoretical Ideas}
\renewcommand\S{{\mathcal S}}
\renewcommand\O{{\mathcal O}}
\newcommand\A{{\mathcal A}}

  Focusing on the problem in the zero-shot coordination setting that agents are unable to coordinate on how to bread symmetries, \cite{hu2020other} proposed ``other-play'' to make the model invariant to symmetries in the underlying MDP.

  The symmetries in the MDP can be described as a permutation group over states $\S$, observations $\O$ and actions $\A$ that keeps the transition function $P$, the reward $R$ and the observation function $O$ invariant. What OP results is essentially a model that doesn't break this symmetry. We can achieve this goal more straightforwardly by designing the networks to be symmetric according to this permutation group.

  For example, in Hanabi, there is a $S_5$ symmetry on 5 colors of the cards. Then the network should comform to $S_5$, satisfying:
  \begin{itemize}
	\item For every neuron $h$ in the network, there should also be neurons $\phi(h)$ for all $\phi\in S_5$.
	\item $h$ and $\phi(h)$ should have the same bias. If $h$ takes its input from a neuron $g$ with weight $\alpha$, then $\phi(h)$ takes input from $\phi(g)$ with the same weight.
  \end{itemize}

  Hence, we see neurons can be seen as devided into equivalence classes $S_5h = \{\phi(h)~|~\phi\in S_5\}$, where they share a same set of weights and bias among the same class. The sizes of these equivalent classes are at most 120.

  We construct a network in which neurons are named by $h_{t,i,\tau}$ where $t$ is the number of the layer, and $\tau\in T_{t,i}$ where $T_{t,i}$ is a set that $S_5$ can act on. Let $\phi(h_{t,i,\tau})=h_{t,i,\phi(tau)}$ and this will meet the conditions.

  This way of constructing a network apply to various types of neurons including LSTM cells.

\section{Further Directions}
For experimental directions, we plan to train models under some more various settings and compare their performances. In order to see the differences explicitly, we may slightly extend the number of epoches to train when time allows. If possible, we may modify some of the codes using our theoretical ideas. This might be hard since there's almost no comments in the code, which makes the code hard to understand.

Moreover, we find that our inital goals seem too far away. Therefore, we are going to restrict the problem settings (for example, we shall focus on 2-player settings) and try to find out something more specific.

If the experimental tasks are still too hard, we may change our focus on theoretical ideas. We may read more papers about Hanabi, understand their ideas more clearly, and think about why such settings have better performance than others.

\normalem
\bibliographystyle{apacite}
\bibliography{papers}
\end{document}
